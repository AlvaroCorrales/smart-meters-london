{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import networkx as nx\n",
    "from dowhy import CausalModel\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNetCV  \n",
    "from sklearn.linear_model import LassoCV   \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = pd.read_csv('Processed data/valid_data_fe.csv')\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DiD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dependent and independent variable matrices\n",
    "X = df_daily.drop(columns=['LCLid', 'Date', 'kwh_hh', 'Acorn', 'got_high_signal', 'got_low_signal', 'high_signal_intensity', 'low_signal_intensity', 'is_weekend'])\n",
    "X = X.drop([col for col in X.columns if col.startswith('month')], axis=1) # Drop months\n",
    "X = sm.add_constant(X)\n",
    "y = df_daily['kwh_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit(cov_type='HC1')\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoWhy + EconML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# List of causes\n",
    "causes = ['day_of_week_Monday',\n",
    "       'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday',\n",
    "       'day_of_week_Tuesday', 'day_of_week_Wednesday', 'temp',\n",
    "       'feelslike', 'precip', 'cloudcover', 'Acorn_enc'] \n",
    "       \n",
    "# Add edges from each cause to 'kwh_hh'\n",
    "for cause in causes:\n",
    "    G.add_edge(cause, 'kwh_hh')\n",
    "\n",
    "# Add the path from treat to treat_2013 to kwh_hh \n",
    "# Actual treatment variable is treat_2013, but treated households were already different in 2012\n",
    "G.add_edges_from([\n",
    "    ('treat', 'treat_2013'),\n",
    "    ('treat_2013', 'kwh_hh'),\n",
    "])\n",
    "\n",
    "G.add_edges_from([\n",
    "    ('treat', 'kwh_hh'),\n",
    "])\n",
    "\n",
    "# We have reasons to believe that treatment assignment may have depended on accorn status\n",
    "G.add_edges_from([\n",
    "    ('Acorn_enc', 'treat')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Use shell layout for a more circular, cleaner arrangement\n",
    "pos = nx.circular_layout(G) \n",
    "\n",
    "# Draw nodes with a color gradient and different sizes based on their degree\n",
    "node_sizes = [3000 if node == 'kwh_hh' else 2000 for node in G.nodes()]\n",
    "node_colors = ['lightgreen' if node == 'kwh_hh' else 'skyblue' for node in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, edgecolors='black')\n",
    "\n",
    "# Draw edges with arrows and custom width/color\n",
    "nx.draw_networkx_edges(G, pos, arrowstyle='-|>', arrowsize=45, edge_color='gray', width=2)\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_color='black', font_weight='bold')\n",
    "\n",
    "# Remove axis for a cleaner look\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the graph\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/whole_network.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CausalModel(\n",
    "   data=df_daily, \n",
    "   treatment=['treat_2013'],  # Actual treatment, whose effect we want to quantify\n",
    "   common_causes = ['treat'], # Treated households were already different in 2012\n",
    "   effect_modifiers=causes,\n",
    "   outcome=\"kwh_hh\",\n",
    "   graph=\"\\n\".join(nx.generate_gml(G))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.view_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_estimate = model.estimate_effect(identified_estimand, \n",
    "                                    method_name=\"backdoor.econml.dml.DML\",\n",
    "                                    control_value = 0,\n",
    "                                    treatment_value = 1,\n",
    "                                    #  target_units = lambda df_daily: df_daily[\"Acorn_enc\"]>=15,  # condition used for CATE\n",
    "                                    confidence_intervals=False,\n",
    "                                    method_params={\"init_params\":{'model_y': GradientBoostingRegressor(random_state=42),\n",
    "                                                                'model_t': GradientBoostingRegressor(random_state=42),\n",
    "                                                                'featurizer':PolynomialFeatures(degree=2, include_bias=False),\n",
    "                                                                'model_final': LassoCV(random_state=42),\n",
    "                                                                'random_state': 42},\n",
    "                                                    \"fit_params\":{}}\n",
    "                                    )\n",
    "print(dml_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_estimate.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refute estimate\n",
    "WARNING - High memory use. These three cells can take a lot of time to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a random common cause variable\n",
    "res_random=model.refute_estimate(identified_estimand, dml_estimate, method_name=\"random_common_cause\", show_progress_bar=True)\n",
    "print(res_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing treatment with a random (placebo) variable\n",
    "res_placebo=model.refute_estimate(identified_estimand, dml_estimate,\n",
    "        method_name=\"placebo_treatment_refuter\", show_progress_bar=True, placebo_type=\"permute\")\n",
    "print(res_placebo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing random subset of the data\n",
    "res_subset=model.refute_estimate(identified_estimand, dml_estimate,\n",
    "        method_name=\"data_subset_refuter\", show_progress_bar=True, subset_fraction=0.9)\n",
    "print(res_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate models for each type of price signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new directed graph\n",
    "G_alt = nx.DiGraph()\n",
    "\n",
    "# List of causes\n",
    "causes = ['day_of_week_Monday',\n",
    "       'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday',\n",
    "       'day_of_week_Tuesday', 'day_of_week_Wednesday', 'temp',\n",
    "       'feelslike', 'precip', 'cloudcover', 'Acorn_enc'] \n",
    "       \n",
    "# Add edges from each cause to 'kwh_hh'\n",
    "for cause in causes:\n",
    "    G_alt.add_edge(cause, 'kwh_hh')\n",
    "\n",
    "# Add the paths described in the question\n",
    "# Path 1: treat to treatment in 2013 to getting high signal to consumption\n",
    "G_alt.add_edges_from([\n",
    "    ('treat', 'treat_2013'),\n",
    "    ('treat_2013', 'got_high_signal'),\n",
    "    ('got_high_signal', 'kwh_hh')\n",
    "])\n",
    "\n",
    "# Path 2: treat to treatment in 2013 to getting low signal to consumption\n",
    "G_alt.add_edges_from([\n",
    "    ('treat', 'treat_2013'),\n",
    "    ('treat_2013', 'got_low_signal'),\n",
    "    ('got_low_signal', 'kwh_hh')\n",
    "])\n",
    "\n",
    "# Even though our treatment here will be the type of signal received (if any), \n",
    "# knowing to be part of treatment group may have an impact on energy consumption\n",
    "G_alt.add_edges_from([\n",
    "    ('treat', 'treat_2013'),\n",
    "    ('treat_2013', 'kwh_hh'),\n",
    "])\n",
    "\n",
    "# Again, treatment group was already different before 2013\n",
    "G_alt.add_edges_from([\n",
    "    ('treat', 'kwh_hh'),\n",
    "])\n",
    "\n",
    "# Again, it doesn't look like treatment was fully randomised\n",
    "G_alt.add_edges_from([\n",
    "    ('Acorn_enc', 'treat')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Use shell layout for a more circular, cleaner arrangement\n",
    "pos = nx.circular_layout(G_alt) \n",
    "\n",
    "# Draw nodes with a color gradient and different sizes based on their degree\n",
    "node_sizes = [3000 if node == 'kwh_hh' else 2000 for node in G_alt.nodes()]\n",
    "node_colors = ['lightgreen' if node == 'kwh_hh' else 'skyblue' for node in G_alt.nodes()]\n",
    "nx.draw_networkx_nodes(G_alt, pos, node_size=node_sizes, node_color=node_colors, edgecolors='black')\n",
    "\n",
    "# Draw edges with arrows and custom width/color\n",
    "nx.draw_networkx_edges(G_alt, pos, arrowstyle='-|>', arrowsize=45, edge_color='gray', width=2)\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(G_alt, pos, font_size=12, font_color='black', font_weight='bold')\n",
    "\n",
    "# Remove axis for a cleaner look\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the graph\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/whole_network_signals.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low price signal model\n",
    "# Step 1. Define model\n",
    "model_low = CausalModel(\n",
    "   data=df_daily, # some pandas dataframe\n",
    "   treatment=['got_low_signal'],\n",
    "   common_causes = ['treat', 'treat_2013'],\n",
    "   effect_modifiers=causes,\n",
    "   outcome=\"kwh_hh\",\n",
    "   graph=\"\\n\".join(nx.generate_gml(G_alt))\n",
    ")\n",
    "\n",
    "# Step 2. Identify estimand\n",
    "identified_estimand_low = model_low.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand_low)\n",
    "\n",
    "# Step 3. Quantify causal estimate\n",
    "causal_estimate_low = model_low.estimate_effect(identified_estimand_low, \n",
    "                                    method_name=\"backdoor.econml.dml.DML\",\n",
    "                                    control_value = 0,\n",
    "                                    treatment_value = 1,\n",
    "                                    confidence_intervals=False,\n",
    "                                    method_params={\"init_params\":{'model_y': GradientBoostingRegressor(random_state=42),\n",
    "                                                                'model_t': GradientBoostingRegressor(random_state=42),\n",
    "                                                                'featurizer':PolynomialFeatures(degree=2, include_bias=False),\n",
    "                                                                'model_final': ElasticNetCV(random_state=42),\n",
    "                                                                'random_state': 42},\n",
    "                                                    \"fit_params\":{}}\n",
    "                                    )\n",
    "print('Causal estimate value:', round(causal_estimate_low.value, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High price signal model\n",
    "# Step 1. Define model\n",
    "model_high = CausalModel(\n",
    "   data=df_daily, # some pandas dataframe\n",
    "   treatment=['got_high_signal'],\n",
    "   common_causes = ['treat', 'treat_2013'],\n",
    "   effect_modifiers=causes.append('Acorn_enc'),\n",
    "   outcome=\"kwh_hh\",\n",
    "   graph=\"\\n\".join(nx.generate_gml(G_alt))\n",
    ")\n",
    "\n",
    "# Step 2. Identify estimand\n",
    "identified_estimand_high = model_high.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand_high)\n",
    "\n",
    "# Step 3. Quantify causal estimate\n",
    "causal_estimate_high = model_high.estimate_effect(identified_estimand_high, \n",
    "                                    method_name=\"backdoor.econml.dml.DML\",\n",
    "                                    control_value = 0,\n",
    "                                    treatment_value = 1,\n",
    "                                    confidence_intervals=False,\n",
    "                                    method_params={\"init_params\":{'model_y': GradientBoostingRegressor(random_state=42),\n",
    "                                                                'model_t': GradientBoostingRegressor(random_state=42),\n",
    "                                                                'featurizer':PolynomialFeatures(degree=2, include_bias=False),\n",
    "                                                                'model_final': ElasticNetCV(random_state=42),\n",
    "                                                                'random_state': 42},\n",
    "                                                    \"fit_params\":{}}\n",
    "                                    )\n",
    "print('Causal estimate value:', round(causal_estimate_high.value, 4))\n",
    "# print('Causal estimate value:', causal_estimate_high.get_confidence_intervals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_high.view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA - Calculating consumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_effect = 0.2565\n",
    "\n",
    "# Keep only 2013\n",
    "df_days = df_daily.copy()\n",
    "df_days['Date'] = pd.to_datetime(df_days['Date'])\n",
    "df_days = df_days[df_days['Date'].dt.year == 2013]\n",
    "\n",
    "# Add \"saved energy\" to treated households\n",
    "df_days['kwh_hh_alt'] = np.where(df_days['treat'] == 1, df_days['kwh_hh'] + treatment_effect, df_days['kwh_hh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption totals \n",
    "actual_cons = df_days['kwh_hh'][df_days['treat']==1].sum()          # Actual consumption\n",
    "potential_cons = df_days['kwh_hh_alt'][df_days['treat']==1].sum()   # Counterfactual consumption - what would have been consumed where it not for the DToU tariff\n",
    "diff_cons = actual_cons - potential_cons                            # Difference between actual and counterfactual consumption\n",
    "\n",
    "print('Actual consumption:', actual_cons)\n",
    "print('Potential consumption:', potential_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per household totals\n",
    "print('Average expenditure difference:', diff_cons * 14.228 / 100 / 77)\n",
    "print('Average energy difference:', diff_cons / 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average household consumption in 2013\n",
    "total_cons = df_days.groupby(['LCLid'])['kwh_hh'].sum()\n",
    "total_cons.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idealista",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
